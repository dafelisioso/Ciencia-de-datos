{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Acosta Imandt Daniel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4Lqth-lZvOq"
      },
      "source": [
        "# Sklearn - Clasificador de Bayes\n",
        "## Caso de estudio: Experimento de conjunto de datos de flores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhZIWTcEZvOx"
      },
      "source": [
        "<b>Conjunto de datos de flores de 17 categorías</b>:\n",
        "\n",
        "<p>Se ha creado un conjunto de datos de flores de 17 categorías con 80 imágenes para cada clase. Las flores elegidas son algunas flores comunes en el Reino Unido. Las imágenes tienen variaciones de gran escala, pose y luz y también hay clases con grandes variaciones de imágenes dentro de la clase y una gran similitud con otras clases. Las categorías se pueden ver en la siguiente figura. Dividimos aleatoriamente el conjunto de datos en 3 conjuntos diferentes de entrenamiento, validación y prueba. Se ha etiquetado un subconjunto de las imágenes para la segmentación.</p>\n",
        "\n",
        "<p>Ver el artículo de referencia y descargar el conjunto de datos: <a href=\"https://www.robots.ox.ac.uk/~vgg/data/flowers/17/\">click aquí</a></p>\n",
        "\n",
        "<h3>Descarga el conjunto de datos</h3> <p>Aquí hay un experimento simple. Solo descargué 1360 conjuntos de datos (58M de tamaño, 40 de cada uno de los 17 tipos de flores y una lista de nombres de imágenes txt) <a href=\"https://www.robots.ox.ac.uk/~vgg/data/flowers/17/17flowers.tgz\">click aquí</a></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ml8cwr4GZvO2"
      },
      "source": [
        "![imagen.png](attachment:imagen.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfUwP5b-ZvO6"
      },
      "source": [
        "De acuerdo con el par txt, cada 40 hojas se clasifican en diferentes carpetas. A continuación moveremos las imagenes para sus carpetas a partir de dicha clasificación. \n",
        "\n",
        "<code>shutil.move()</code> Mover archivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MTDbS6J-ZvPB"
      },
      "outputs": [],
      "source": [
        "\"\"\"1. Descargue 17 tipos de imágenes de datos de flores, cada 40 imágenes se ordenan en una carpeta\n",
        " Enlace de descarga: http://www.robots.ox.ac.uk/~vgg/data/flowers/17/\n",
        "\"\"\"\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "n=0\n",
        "label=0\n",
        "with open(\"jpg/files.txt\", \"r\") as f:\n",
        "    for line in f.readlines():\n",
        "        if n < 40:\n",
        "            n = n + 1\n",
        "        else:\n",
        "            label = label + 1\n",
        "            n = 0\n",
        "        path = 'jpg/{}'.format(line.replace(\"\\n\", \"\"))\n",
        "        path2 = 'train/{}/'.format(label) # es lo mismo que decir: 'train/'+str(label)+'/'\n",
        "        if not os.path.exists(path2):\n",
        "            os.makedirs(path2)\n",
        "        shutil.move(path, path2 + line.replace(\"\\n\", \"\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erlYwvKbZvPF"
      },
      "source": [
        "<p>Resultado obtenido</p>\n",
        "\n",
        "![imagen.png](attachment:imagen.png)\n",
        "\n",
        "<p>Para este caso elegiremos un conjunto de 10 categorías. El elemento X que se clasifica tiene 10 * 40 = 400 imágenes: (tomamos las 10 principales especies de flores).</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB6HtyYTZvPJ"
      },
      "source": [
        "![imagen.png](attachment:imagen.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quECgzWwZvPL"
      },
      "source": [
        "<b>Método ingenuo de Bayes:</b> Es un método de clasificación basado en el teorema de Bayes y el supuesto de independencia de las condiciones características. Es decir, se supone que los atributos son condicionalmente independientes entre sí cuando se da el valor objetivo. Es decir, ninguna variable de atributo tiene una proporción mayor del resultado de la decisión y ninguna variable de atributo tiene una proporción menor del resultado de la decisión.\n",
        "\n",
        "<b>La clasificación de Naive Bayes se divide en tres etapas</b>\n",
        "<ul>\n",
        "    <li>El primer escenario--<code>Etapa de preparación</code> La tarea en esta etapa es hacer los preparativos necesarios para la clasificación de Bayes ingenua. El trabajo principal es determinar los atributos de las características de acuerdo con la situación específica, y dividir adecuadamente cada atributo de las características, y luego clasificar manualmente algunos de los elementos que se clasificarán para formar la capacitación. Coleccion de muestra. La entrada de esta etapa son todos los datos que se van a clasificar y la salida son los atributos de las características y las muestras de entrenamiento. Esta etapa es la única etapa que debe completarse manualmente en toda la clasificación Bayesiana ingenua. Su calidad tendrá un impacto importante en todo el proceso. La calidad del clasificador está determinada en gran medida por los atributos de las características, la división de atributos de las características y la calidad de la muestra de entrenamiento.</li>\n",
        "    <li>Segunda etapa--<code>Fase de entrenamiento del clasificador</code> La tarea de esta etapa es generar un clasificador, el trabajo principal es calcular la frecuencia de cada categoría en la muestra de entrenamiento y la estimación de probabilidad condicional de cada división de atributo de característica para cada categoría, y registrar los resultados. La entrada son los atributos de características y las muestras de entrenamiento, y la salida es el clasificador. Esta etapa es una etapa mecánica, que el programa puede calcular automáticamente de acuerdo con la fórmula descrita anteriormente.</li>\n",
        "    <li>La tercera etapa <code>Fase de aplicación</code> La tarea de esta etapa es utilizar el clasificador para clasificar los artículos a clasificar, la entrada es el clasificador y los artículos a clasificar, y la salida es la relación de mapeo entre los artículos a clasificar y la categoría. Esta etapa también es una etapa mecánica y se completa por programa.</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3YNgDuSNZvPO",
        "outputId": "c544cc50-31fa-41ed-ae53-014cccea0f85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "286 123 286 123\n",
            "Resultado del pronóstico:\n",
            "[6 2 6 6 3 4 4 0 3 7 6 2 0 6 8 9 8 7 4 4 0 4 0 2 4 4 7 8 4 4 2 9 1 4 6 6 5\n",
            " 0 2 7 9 8 4 2 4 6 0 8 7 4 7 7 8 3 5 3 2 7 3 4 8 3 2 0 6 4 0 2 3 4 7 4 6 8\n",
            " 4 4 6 4 3 3 0 8 7 0 7 9 4 8 1 7 1 6 0 2 6 0 7 4 7 4 3 6 5 7 3 2 3 4 9 9 7\n",
            " 1 2 6 5 6 6 8 2 4 8 9 2]\n",
            "Evaluación del algoritmo:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.64      0.61        11\n",
            "           1       0.25      0.11      0.15         9\n",
            "           2       0.43      0.43      0.43        14\n",
            "           3       0.17      0.33      0.22         6\n",
            "           4       0.16      0.40      0.23        10\n",
            "           5       0.00      0.00      0.00        15\n",
            "           6       0.47      0.62      0.53        13\n",
            "           7       0.38      0.38      0.38        16\n",
            "           8       0.25      0.21      0.23        14\n",
            "           9       0.71      0.33      0.45        15\n",
            "\n",
            "    accuracy                           0.34       123\n",
            "   macro avg       0.34      0.34      0.32       123\n",
            "weighted avg       0.35      0.34      0.33       123\n",
            "\n",
            "Informe de clasificación de tipo de diccionario de la segunda imagen:\n",
            "precision :      0.25\n",
            "recall    :      0.11\n",
            "f1-score  :      0.15\n",
            "support   :      9.00\n",
            "train/8/image_0350.jpg\n",
            "6\n",
            "train/4/image_0181.jpg\n",
            "2\n",
            "train/6/image_0271.jpg\n",
            "6\n",
            "train/7/image_0290.jpg\n",
            "6\n",
            "train/2/image_0082.jpg\n",
            "3\n",
            "train/2/image_0086.jpg\n",
            "4\n",
            "train/1/image_0068.jpg\n",
            "4\n",
            "train/0/image_0030.jpg\n",
            "0\n",
            "train/8/image_0348.jpg\n",
            "3\n",
            "train/8/image_0330.jpg\n",
            "7\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Clasificación y reconocimiento de Naive Bayes\n",
        "\n",
        "1. Conjunto de entrenamiento dividido y conjunto de prueba:\n",
        "    Las 400 imágenes se dividen aleatoriamente en el 70% del conjunto de entrenamiento (286 imágenes) \n",
        "     y el 30% del conjunto de prueba (123 imágenes).\n",
        "     \n",
        "2. Lectura de imágenes y conversión aHistograma de píxeles\n",
        "     Aquí está el estándar de extracción de características, aquí usaremos temporalmente la característica de histograma \n",
        "     para extraer (obtendremos el histograma de píxeles de cada imagen), simplificar el proceso; \n",
        "     en el uso real, el estándar de extracción aquí debería ser su función de extracción de características de \n",
        "     optimización personalizada.\n",
        "    \n",
        "3. Procesamiento de clasificación de imágenes basado en Naive Bayes \n",
        "    Realizaremos la clasificación y el análisis de imágenes de acuerdo con la distribución de características de los píxeles.\n",
        "\"\"\"\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "#----------------------------------------------------------------------------------\n",
        "# El primer paso es dividir el conjunto de entrenamiento y el conjunto de prueba\n",
        "#----------------------------------------------------------------------------------\n",
        "\n",
        "X = [] # Definir el nombre de la imagen\n",
        "Y = [] # Definir clasificación de imágenes\n",
        "#Z = [] # definir píxeles de imagen\n",
        "\n",
        "for i in range(0, 10):\n",
        "    # Atravesar carpetas, leer imágenes\n",
        "    for f in os.listdir(\"train/%s\" % i):\n",
        "        # Obtener nombre de imagen\n",
        "        X.append(\"train/\" +str(i) + \"/\" + str(f))\n",
        "        # Obtener la etiqueta de categoría de imagen es el nombre de la carpeta\n",
        "        Y.append(i)\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "# La tasa aleatoria es del 100%, 30% de los cuales se seleccionan como conjunto de prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y,test_size=0.3, random_state=1)\n",
        "\n",
        "print(len(X_train), len(X_test), len(y_train), len(y_test))\n",
        "\n",
        "#----------------------------------------------------------------------------------\n",
        "# Paso 2 Lectura de imágenes y conversión a histograma de píxeles\n",
        "#----------------------------------------------------------------------------------\n",
        "\n",
        "#Conjunto de entrenamiento\n",
        "XX_train = []\n",
        "for i in X_train:\n",
        "    # Leer imagen\n",
        "    # print(i)\n",
        "    image = cv2.imread(i)\n",
        "    \n",
        "    # El tamaño del píxel de la imagen es consistente\n",
        "    img = cv2.resize(image, (256,256), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # Calcular el histograma de la imagen y almacenarlo en la matriz X\n",
        "    hist = cv2.calcHist([img], [0,1], None, [256,256], [0.0,255.0,0.0,255.0])\n",
        "\n",
        "    XX_train.append(((hist/255).flatten()))\n",
        "\n",
        "# Equipo de prueba\n",
        "XX_test = []\n",
        "for i in X_test:\n",
        "    # Leer imagen\n",
        "    # print(i)\n",
        "    image = cv2.imread(i)\n",
        "    \n",
        "    # El tamaño del píxel de la imagen es consistente\n",
        "    img = cv2.resize(image, (256,256), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    #Calcular el histograma de la imagen y almacenarlo en la matriz X\n",
        "    hist = cv2.calcHist([img], [0,1], None, [256,256], [0.0,255.0,0.0,255.0])\n",
        "\n",
        "    XX_test.append(((hist/255).flatten()))\n",
        "\n",
        "#----------------------------------------------------------------------------------\n",
        "# Tercer paso Procesamiento de clasificación de imágenes basado en Naive Bayes\n",
        "#----------------------------------------------------------------------------------\n",
        "\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "# Usa el conjunto de entrenamiento para entrenar al modelo\n",
        "clf = BernoulliNB().fit(XX_train, y_train) # Clasificador Bernoulli Bayes\n",
        "predictions_labels = clf.predict(XX_test)\n",
        "\n",
        "# Utilice el conjunto de pruebas para predecir resultados\n",
        "print('Resultado del pronóstico:')\n",
        "print(predictions_labels)\n",
        "\n",
        "# Generar informe de clasificación basado en texto\n",
        "print('Evaluación del algoritmo:') # Exactitud de la evaluación de algoritmos (precisión), recuperación (recuperación) y valor F (puntuación F1)\n",
        "print((classification_report(y_test, predictions_labels)))\n",
        "\n",
        "# Generar informe de clasificación de tipo de diccionario\n",
        "report = classification_report(y_test, predictions_labels, output_dict=True)\n",
        "print('Informe de clasificación de tipo de diccionario de la segunda imagen:')\n",
        "for key, value in report[\"1\"].items():\n",
        "    print(f\"{key:10s}:{value:10.2f}\")\n",
        "    \n",
        "# Obtenga las primeras 10 imágenes y los resultados de la predicción\n",
        "k = 0\n",
        "while k < 10:\n",
        "    # Leer imagen\n",
        "    print(X_test[k])\n",
        "    image = cv2.imread(X_test[k])\n",
        "    print(predictions_labels[k])\n",
        "    \n",
        "    # Mostrar imagen\n",
        "    cv2.imshow(\"img\", image)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "    k = k + 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMPMG79IZvPW"
      },
      "source": [
        "Dos de los primeros diez resultados de predicción son correctos, porque nuestras muestras de entrenamiento son muy pocas y la extracción de características solo depende del histograma como factor de juicio, por lo que la precisión aquí no es alta.\n",
        "\n",
        "![imagen.png](attachment:imagen.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uibeXhIZvPY"
      },
      "source": [
        "¿Y si queremos guardar/almacenar dicho clasificador? ¿Cómo le haríamos para posteriormente usarlo en futuras predicciones?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: joblib in c:\\users\\danie\\anaconda3\\lib\\site-packages (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "XjVG2OEGZvPa"
      },
      "outputs": [],
      "source": [
        "# Usaremos esta librería incorporada en sklearn\n",
        "import joblib\n",
        "\n",
        "# Almacenamos el clasificador en un archivo\n",
        "filename = 'classifier.joblib.pkl'\n",
        "_ = joblib.dump(clf, filename, compress=9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "vQiDbPfrZvPe",
        "outputId": "f654d686-5cd1-4685-c996-04c6f57b913b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BernoulliNB()"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Leeremos el archivo almacenado\n",
        "clf2 = joblib.load(filename)\n",
        "clf2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KDc-I3CLZvPi",
        "outputId": "21e461dd-2929-4245-d75c-165c5343981d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resultado del pronóstico:\n",
            "[6 2 6 6 3 4 4 0 3 7 6 2 0 6 8 9 8 7 4 4 0 4 0 2 4 4 7 8 4 4 2 9 1 4 6 6 5\n",
            " 0 2 7 9 8 4 2 4 6 0 8 7 4 7 7 8 3 5 3 2 7 3 4 8 3 2 0 6 4 0 2 3 4 7 4 6 8\n",
            " 4 4 6 4 3 3 0 8 7 0 7 9 4 8 1 7 1 6 0 2 6 0 7 4 7 4 3 6 5 7 3 2 3 4 9 9 7\n",
            " 1 2 6 5 6 6 8 2 4 8 9 2]\n",
            "Evaluación del algoritmo:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.64      0.61        11\n",
            "           1       0.25      0.11      0.15         9\n",
            "           2       0.43      0.43      0.43        14\n",
            "           3       0.17      0.33      0.22         6\n",
            "           4       0.16      0.40      0.23        10\n",
            "           5       0.00      0.00      0.00        15\n",
            "           6       0.47      0.62      0.53        13\n",
            "           7       0.38      0.38      0.38        16\n",
            "           8       0.25      0.21      0.23        14\n",
            "           9       0.71      0.33      0.45        15\n",
            "\n",
            "    accuracy                           0.34       123\n",
            "   macro avg       0.34      0.34      0.32       123\n",
            "weighted avg       0.35      0.34      0.33       123\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Utilizaremos el clasificador almacenado\n",
        "predictions_labels2 = clf2.predict(XX_test)\n",
        "\n",
        "# Utilice el conjunto de pruebas para predecir resultados\n",
        "print('Resultado del pronóstico:')\n",
        "print(predictions_labels2)\n",
        "\n",
        "# Generar informe de clasificación basado en texto\n",
        "print('Evaluación del algoritmo:') # Exactitud de la evaluación de algoritmos (precisión), recuperación (recuperación) y valor F (puntuación F1)\n",
        "print((classification_report(y_test, predictions_labels2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEuMqzeRZvPm"
      },
      "source": [
        "### Actividad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOAwOKnNZvPm"
      },
      "source": [
        "#### 1. Investigue qué significa el parámetro de <code> alpha </code> en el método del clasificador de Bayes utilizado desde la biblioteca de scikit-learn.\n",
        "\n",
        "#### 2. Realice al menos 2 pruebas (2 clasificadores del clasificador de Bayes) moviéndole los parámetros que tiene incorporado el mismo en su implementación (ver la documentación oficial) y obtenga la evaluación de cada uno de los experimientos realizados. Trate de darle una justificación al cambio de dichos parámetros\n",
        "\n",
        "Referencia: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html#sklearn.naive_bayes.BernoulliNB\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1) \n",
        "Alpha es un hiperparámetro, ya que controla la forma en que se comporta el modelo.Este nos suele servir como un parámetro de suavizado que hace que se eviten outliers y probabilidades cercanas a cero.\n",
        "Para encontrar el mejor de alpha se suele hacer a través de una busqueda de los valores que puede tomar, iusando validazión cruzada y viendo cada resultado obtendio así encotramos el mejor. \n",
        "\n",
        "2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "aiZ-BPXWZvPn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resultado del pronóstico:\n",
            "[6 2 6 6 2 4 4 0 3 7 6 2 0 6 8 9 8 7 4 4 0 4 0 2 4 4 7 8 4 5 2 9 1 4 6 6 5\n",
            " 0 2 7 9 8 4 2 4 6 0 8 8 4 7 7 8 3 5 9 2 9 3 4 8 3 2 0 6 4 0 2 3 4 7 5 6 8\n",
            " 4 4 6 4 3 3 0 8 7 0 7 9 4 8 1 7 1 6 0 2 6 0 7 4 7 4 4 6 8 7 3 2 3 4 9 9 7\n",
            " 1 2 6 5 6 6 8 2 4 8 9 2]\n",
            "Evaluación del algoritmo:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.64      0.61        11\n",
            "           1       0.25      0.11      0.15         9\n",
            "           2       0.47      0.50      0.48        14\n",
            "           3       0.22      0.33      0.27         6\n",
            "           4       0.17      0.40      0.24        10\n",
            "           5       0.20      0.07      0.10        15\n",
            "           6       0.47      0.62      0.53        13\n",
            "           7       0.43      0.38      0.40        16\n",
            "           8       0.21      0.21      0.21        14\n",
            "           9       0.56      0.33      0.42        15\n",
            "\n",
            "    accuracy                           0.36       123\n",
            "   macro avg       0.36      0.36      0.34       123\n",
            "weighted avg       0.37      0.36      0.35       123\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "# Usa el conjunto de entrenamiento para entrenar al modelo\n",
        "clf = BernoulliNB(alpha=0.35).fit(XX_train, y_train) # Clasificador Bernoulli Bayes\n",
        "predictions_labels = clf.predict(XX_test)\n",
        "\n",
        "# Utilice el conjunto de pruebas para predecir resultados\n",
        "print('Resultado del pronóstico:')\n",
        "print(predictions_labels)\n",
        "\n",
        "# Generar informe de clasificación basado en texto\n",
        "print('Evaluación del algoritmo:') # Exactitud de la evaluación de algoritmos (precisión), recuperación (recuperación) y valor F (puntuación F1)\n",
        "print((classification_report(y_test, predictions_labels)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resultado del pronóstico:\n",
            "[6 2 6 6 3 4 4 0 3 7 6 2 0 6 8 9 8 7 4 4 0 4 0 2 4 4 7 8 4 4 2 9 1 4 6 6 5\n",
            " 0 2 7 9 8 4 2 4 6 0 8 7 4 7 7 8 3 5 3 2 7 3 4 8 3 2 0 6 4 0 2 3 4 7 4 6 8\n",
            " 4 4 6 4 3 3 0 8 7 0 7 9 4 8 1 7 1 6 0 2 6 0 7 4 7 4 3 6 5 7 3 2 3 4 9 9 7\n",
            " 1 2 6 5 6 6 8 2 4 8 9 2]\n",
            "Evaluación del algoritmo:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.64      0.61        11\n",
            "           1       0.25      0.11      0.15         9\n",
            "           2       0.43      0.43      0.43        14\n",
            "           3       0.17      0.33      0.22         6\n",
            "           4       0.16      0.40      0.23        10\n",
            "           5       0.00      0.00      0.00        15\n",
            "           6       0.47      0.62      0.53        13\n",
            "           7       0.38      0.38      0.38        16\n",
            "           8       0.25      0.21      0.23        14\n",
            "           9       0.71      0.33      0.45        15\n",
            "\n",
            "    accuracy                           0.34       123\n",
            "   macro avg       0.34      0.34      0.32       123\n",
            "weighted avg       0.35      0.34      0.33       123\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Usa el conjunto de entrenamiento para entrenar al modelo\n",
        "clf = BernoulliNB(alpha=0.9).fit(XX_train, y_train) # Clasificador Bernoulli Bayes\n",
        "predictions_labels = clf.predict(XX_test)\n",
        "\n",
        "# Utilice el conjunto de pruebas para predecir resultados\n",
        "print('Resultado del pronóstico:')\n",
        "print(predictions_labels)\n",
        "\n",
        "# Generar informe de clasificación basado en texto\n",
        "print('Evaluación del algoritmo:') # Exactitud de la evaluación de algoritmos (precisión), recuperación (recuperación) y valor F (puntuación F1)\n",
        "print((classification_report(y_test, predictions_labels)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resultado del pronóstico:\n",
            "[6 2 6 6 2 4 1 0 3 6 6 9 0 8 8 9 9 7 5 5 0 4 0 4 4 4 7 8 5 0 2 9 1 4 6 6 9\n",
            " 0 3 7 9 8 4 3 5 6 0 8 8 4 9 8 8 4 5 9 3 9 3 4 8 3 2 0 6 4 0 2 4 4 7 5 6 8\n",
            " 4 4 6 4 3 3 0 8 7 0 7 9 4 8 1 7 1 6 0 2 6 0 6 4 7 4 4 6 8 7 9 2 9 4 9 9 7\n",
            " 1 2 6 5 6 6 8 9 4 8 9 2]\n",
            "Evaluación del algoritmo:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.73      0.67        11\n",
            "           1       0.40      0.22      0.29         9\n",
            "           2       0.56      0.36      0.43        14\n",
            "           3       0.25      0.33      0.29         6\n",
            "           4       0.27      0.60      0.37        10\n",
            "           5       0.43      0.20      0.27        15\n",
            "           6       0.39      0.54      0.45        13\n",
            "           7       0.60      0.38      0.46        16\n",
            "           8       0.20      0.21      0.21        14\n",
            "           9       0.38      0.40      0.39        15\n",
            "\n",
            "    accuracy                           0.39       123\n",
            "   macro avg       0.41      0.40      0.38       123\n",
            "weighted avg       0.42      0.39      0.39       123\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Usa el conjunto de entrenamiento para entrenar al modelo\n",
        "clf = BernoulliNB(alpha=0.00001).fit(XX_train, y_train) # Clasificador Bernoulli Bayes\n",
        "predictions_labels = clf.predict(XX_test)\n",
        "\n",
        "# Utilice el conjunto de pruebas para predecir resultados\n",
        "print('Resultado del pronóstico:')\n",
        "print(predictions_labels)\n",
        "\n",
        "# Generar informe de clasificación basado en texto\n",
        "print('Evaluación del algoritmo:') # Exactitud de la evaluación de algoritmos (precisión), recuperación (recuperación) y valor F (puntuación F1)\n",
        "print((classification_report(y_test, predictions_labels)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Al hacer algunas pruebas con diferentes valores encontramos que para valores cercanos a 1, es decir cuando existe mayor suavizado el accuracy no es muy bueno, por lo que lo bajamos y mejoro  el resultado, pero no lo suficiente, despues de varias pruebas llegue a que el mejor resultado obtenido en las pruebas fue de  0.00001."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "lab6_bayes_scikit-learn.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "4d9defa72c2715dab9f7f172572cd30a1ab1a2083462d32ef96aadb7c6e0c73b"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
